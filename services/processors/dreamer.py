#!/usr/bin/env python3
"""
MyMem Dreamer (v9.5) - Rebuild Compatible

Nyheter:
- Ã…terstÃ¤llt ReviewObject fÃ¶r kompatibilitet med interactive_review.py.
- consolidate() returnerar nu data (review_list) till orchestratorn.
- Batch-optimering och Aggregerad Konfidens kvarstÃ¥r.
"""

import os
import sys
import json
import yaml
import logging
import datetime
import zoneinfo
import asyncio
from collections import defaultdict
from typing import List, Dict, Optional
from dataclasses import dataclass

sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from google import genai
from google.genai import types
from services.utils.graph_service import GraphStore
from services.utils.json_parser import parse_llm_json

# --- CONFIG LOADER ---
def _load_config():
    script_dir = os.path.dirname(os.path.abspath(__file__))
    paths = [
        os.path.join(script_dir, '..', '..', 'config', 'my_mem_config.yaml'),
        os.path.join(script_dir, '..', 'config', 'my_mem_config.yaml'),
        os.path.join(script_dir, 'config', 'my_mem_config.yaml'),
    ]
    main_conf = {}
    for p in paths:
        if os.path.exists(p):
            with open(p, 'r') as f: main_conf = yaml.safe_load(f)
            for k, v in main_conf.get('paths', {}).items():
                main_conf['paths'][k] = os.path.expanduser(v)
            
            config_dir = os.path.dirname(p)
            prompts_conf = {}
            for name in ['services_prompts.yaml', 'service_prompts.yaml']:
                pp = os.path.join(config_dir, name)
                if os.path.exists(pp):
                    with open(pp, 'r') as f: prompts_conf = yaml.safe_load(f)
                    break
            
            return main_conf, prompts_conf
    raise FileNotFoundError("HARDFAIL: Config saknas")

CONFIG, PROMPTS_RAW = _load_config()

# Helper Functions
def get_prompt(agent, key):
    if 'prompts' in PROMPTS_RAW:
        return PROMPTS_RAW['prompts'].get(agent, {}).get(key)
    return PROMPTS_RAW.get(agent, {}).get(key)

def get_setting(agent, key, default):
    val = PROMPTS_RAW.get('settings', {}).get(agent, {}).get(key)
    if val is not None: return val
    return default

# Settings
GRAPH_PATH = CONFIG['paths']['graph_db']
LAKE_STORE = CONFIG['paths']['lake_store']
TAXONOMY_FILE = CONFIG['paths']['taxonomy_file']
LOG_FILE = CONFIG['logging']['log_file_path']

API_KEY = CONFIG['ai_engine']['api_key']
MODEL_FAST = CONFIG.get('ai_engine', {}).get('models', {}).get('model_fast')

# Batch Settings
BATCH_SIZE = 15
MAX_CONCURRENT_REQUESTS = 5 
MAX_NODE_LENGTH = get_setting('dreamer', 'max_node_name_length', 60)
MAX_CONTEXT_ITEMS_PER_ENTITY = 3

logging.basicConfig(
    filename=LOG_FILE,
    level=logging.INFO,
    format='%(asctime)s - DREAMER - %(levelname)s - %(message)s'
)
LOGGER = logging.getLogger('Dreamer')
AI_CLIENT = genai.Client(api_key=API_KEY)

def _ts():
    return datetime.datetime.now().strftime("[%H:%M:%S]")

# --- DATA STRUCTURES ---

@dataclass
class ReviewObject:
    """Dataclass fÃ¶r entiteter som behÃ¶ver granskas av anvÃ¤ndaren (KrÃ¤vs av interactive_review)."""
    entity_name: str
    master_node: str
    similarity_score: float
    suggested_action: str  # 'APPROVE', 'REVIEW', 'REJECT'
    reason: str
    closest_match: str | None = None

# --- CORE LOGIC CLASS ---
class EvidenceConsolidator:
    def __init__(self):
        self.graph = GraphStore(GRAPH_PATH, read_only=False)
        self.valid_master_nodes = self._load_valid_nodes()

    def _load_valid_nodes(self) -> List[str]:
        if not os.path.exists(TAXONOMY_FILE): return []
        with open(TAXONOMY_FILE, 'r', encoding='utf-8') as f:
            return list(json.load(f).keys())

    def fetch_pending_evidence(self) -> Dict[str, List[Dict]]:
        try:
            results = self.graph.conn.execute("""
                SELECT entity_name, master_node_candidate, context_description, source_file, confidence
                FROM evidence
            """).fetchall()
        except Exception as e:
            LOGGER.error(f"DB Read Error: {e}")
            return {}

        grouped = defaultdict(list)
        for row in results:
            grouped[row[0]].append({
                "master_node": row[1],
                "context": row[2],
                "source_file": row[3],
                "confidence": row[4]
            })
        return grouped

    def _calculate_aggregated_confidence(self, evidence_list: List[Dict]) -> float:
        if not evidence_list: return 0.0
        failure_probability = 1.0
        unique_sources = set()
        for ev in evidence_list:
            src = ev['source_file']
            base_conf = ev.get('confidence', 0.5)
            weight = 0.2 if src in unique_sources else 1.0
            unique_sources.add(src)
            local_risk = 1.0 - (base_conf * weight)
            failure_probability *= local_risk
        return min(1.0 - failure_probability, 0.99)

    def _analyze_batch_sync(self, batch_items: List[tuple]) -> List[Dict]:
        """Analyserar en lista med (entity_name, evidence_list)."""
        raw_prompt = get_prompt('dreamer', 'consolidate_batch')
        if not raw_prompt:
            LOGGER.error("HARDFAIL: Prompt 'consolidate_batch' saknas")
            return []

        candidates_parts = []
        for name, ev_list in batch_items:
            contexts = [f"- [{e['master_node']}] {e['context']}" for e in ev_list[:MAX_CONTEXT_ITEMS_PER_ENTITY]]
            context_str = "\n".join(contexts)
            candidates_parts.append(f"---\nITEM: \"{name}\"\nCONTEXT:\n{context_str}")
        
        candidates_str = "\n".join(candidates_parts)
        valid_nodes_str = ", ".join([f'"{n}"' for n in self.valid_master_nodes])

        prompt = raw_prompt.format(
            candidates_str=candidates_str,
            valid_nodes_str=valid_nodes_str
        )

        try:
            response = AI_CLIENT.models.generate_content(
                model=MODEL_FAST,
                contents=[types.Content(role="user", parts=[types.Part.from_text(text=prompt)])],
                config=types.GenerateContentConfig(response_mime_type="application/json")
            )
            parsed = parse_llm_json(response.text, context="Dreamer_Batch")
            results = parsed.get("results", [])
            
            validated_results = []
            for res in results:
                if res.get('master_node') not in self.valid_master_nodes:
                    continue
                node_id = res.get('suggested_node_id') or res.get('entity')
                if res.get('is_atomic_node') and len(node_id) > MAX_NODE_LENGTH:
                    res['is_atomic_node'] = False
                    res['suggested_node_id'] = None
                validated_results.append(res)
            return validated_results

        except Exception as e:
            LOGGER.error(f"Batch LLM Error: {e}")
            return []

    async def analyze_batch_async(self, batch: List[tuple], semaphore: asyncio.Semaphore) -> List[Dict]:
        async with semaphore:
            return await asyncio.to_thread(self._analyze_batch_sync, batch)

    def commit_to_graph(self, analysis: Dict, source_files: List[str]) -> tuple[bool, str]:
        master_node = analysis['master_node']
        desc = analysis.get('canonical_summary', '')
        
        try:
            self.graph.upsert_node(id=master_node, type="Concept")

            if analysis.get('is_atomic_node'):
                node_id = analysis['suggested_node_id']
                self.graph.upsert_node(
                    id=node_id,
                    type="Entity",
                    aliases=analysis.get('aliases', []),
                    properties={
                        "entity_type": master_node,
                        "description": desc,
                        "last_consolidated": datetime.datetime.now().isoformat()
                    }
                )
                msg = f"ðŸŸ¢ Nod: {node_id} ({master_node})"
                target = node_id
                edge = "UNIT_MENTIONS"
            else:
                msg = f"ðŸ”µ Tema: Kopplat till {master_node}"
                target = master_node
                edge = "DEALS_WITH"

            for src in list(set(source_files)):
                self.graph.upsert_edge(
                    source=src, target=target, edge_type=edge, 
                    properties={"context": desc}
                )
            return True, msg

        except Exception as e:
            LOGGER.error(f"Graph Write Error: {e}")
            return False, str(e)

    def clear_processed_evidence(self, entity_name: str):
        try:
            self.graph.conn.execute("DELETE FROM evidence WHERE entity_name = ?", [entity_name])
        except Exception as e:
            LOGGER.error(f"Cleanup Error: {e}")

    def close(self):
        self.graph.close()

# --- BACKPROPAGATION ---
def backpropagate_to_lake(source_files: List[str], topic: str, summary: str):
    if not source_files: return
    unique_files = list(set(source_files))
    import re
    
    for unit_id in unique_files:
        uuid_match = re.search(r'([0-9a-f]{8}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{12})', unit_id)
        clean_uuid = uuid_match.group(1) if uuid_match else unit_id

        target_file = None
        for f in os.listdir(LAKE_STORE):
            if f.endswith(f"_{clean_uuid}.md"):
                target_file = os.path.join(LAKE_STORE, f)
                break
        
        if not target_file: continue

        try:
            with open(target_file, 'r', encoding='utf-8') as f: content = f.read()
            if "---" not in content: continue
            parts = content.split("---", 2)
            if len(parts) < 3: continue
            
            frontmatter = yaml.safe_load(parts[1]) or {}
            ctx = frontmatter.get('graph_context_summary', "")
            new_item = f"{topic}: {summary}"
            
            if new_item not in ctx:
                if ctx: ctx += f"\n- {new_item}"
                else: ctx = f"- {new_item}"
                frontmatter['graph_context_summary'] = ctx
                frontmatter['graph_context_updated_at'] = datetime.datetime.now().isoformat()
                frontmatter['graph_context_status'] = "consolidated"
                new_fm = yaml.dump(frontmatter, allow_unicode=True, sort_keys=False)
                with open(target_file, 'w', encoding='utf-8') as f:
                    f.write(f"---\n{new_fm}---\n{parts[2]}")
                LOGGER.info(f"Backpropagated till {os.path.basename(target_file)}")
        except Exception as e:
            LOGGER.error(f"Backprop error {target_file}: {e}")

# --- BATCH ORCHESTRATION ---
async def process_all_evidence_batch() -> Dict:
    """
    Returnerar en dict med status och review_list fÃ¶r orkestratorn.
    """
    print(f"{_ts()} ðŸ’­ Dreamer Batch Startar...")
    dreamer = EvidenceConsolidator()
    evidence_groups = dreamer.fetch_pending_evidence()
    
    if not evidence_groups:
        print(f"{_ts()} ðŸ’¤ Inga bevis att bearbeta.")
        dreamer.close()
        return {"status": "OK", "review_list": []}

    candidates = []
    min_evidence = get_setting('dreamer', 'min_evidence_count', 2)
    for name, ev_list in evidence_groups.items():
        if len(ev_list) >= min_evidence or any(e['confidence'] > 0.8 for e in ev_list):
            candidates.append((name, ev_list))
    
    if not candidates:
        dreamer.close()
        return {"status": "OK", "review_list": []}

    print(f"{_ts()} ðŸ” Hittade {len(candidates)} kandidater. Batchar...")
    batches = [candidates[i:i + BATCH_SIZE] for i in range(0, len(candidates), BATCH_SIZE)]
    semaphore = asyncio.Semaphore(MAX_CONCURRENT_REQUESTS)
    tasks = [dreamer.analyze_batch_async(batch, semaphore) for batch in batches]
    
    results_list_of_lists = await asyncio.gather(*tasks)
    all_results = [item for sublist in results_list_of_lists for item in sublist]
    
    stats = {"auto_nodes": 0, "themes": 0, "skipped_uncertain": 0}
    evidence_map = {name: ev_list for name, ev_list in candidates}
    review_list = [] # HÃ¤r samlar vi manuella reviews
    
    for res in all_results:
        entity_name = res.get('entity')
        evidence_list = evidence_map.get(entity_name)
        
        if not evidence_list: continue
            
        is_node = res.get('is_atomic_node')
        agg_conf = dreamer._calculate_aggregated_confidence(evidence_list)
        
        should_commit = False
        if not is_node:
            should_commit = True
            stats["themes"] += 1
        elif agg_conf >= 0.9:
            should_commit = True
            stats["auto_nodes"] += 1
        else:
            # OsÃ¤ker Nod -> Skapa ReviewObject fÃ¶r manuell granskning
            stats["skipped_uncertain"] += 1
            review_obj = ReviewObject(
                entity_name=res.get('suggested_node_id') or entity_name,
                master_node=res.get('master_node'),
                similarity_score=agg_conf,
                suggested_action="REVIEW",
                reason=f"Konfidens ({agg_conf:.2f}) < 0.9",
                closest_match=None 
            )
            review_list.append(review_obj)
            
        if should_commit:
            source_files = [e['source_file'] for e in evidence_list]
            success, msg = dreamer.commit_to_graph(res, source_files)
            if success:
                topic = res.get('suggested_node_id') if is_node else res.get('master_node')
                backpropagate_to_lake(source_files, topic, res.get('canonical_summary', ''))
                dreamer.clear_processed_evidence(entity_name)
                print(f"   {msg}")

    dreamer.close()
    print(f"{_ts()} âœ¨ Klar. {stats['auto_nodes']} noder, {stats['themes']} teman sparade.")
    if review_list:
        print(f"{_ts()} âš ï¸  {len(review_list)} noder skickas till manuell granskning.")
        
    return {
        "status": "OK",
        "review_list": review_list, # Returnera listan!
        "stats": stats
    }

def consolidate():
    """Wrapper som returnerar resultatet (synkront)."""
    return asyncio.run(process_all_evidence_batch())

if __name__ == "__main__":
    consolidate()